[
{"url": "https://blog.scrapinghub.com/data-center-proxies-vs.-residential-proxies", "title": "Data Center Proxies vs. Residential Proxies", "date": "July 21, 2020 ", "author": "Attila T\u00f3th", "no_comment": "0 Comments", "content": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://blog.scrapinghub.com/price-intelligence-questions-answered", "title": "Your Price Intelligence Questions Answered", "date": "July 28, 2020 ", "author": "Himanshi Bhatt", "no_comment": "0 Comments", "content": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Price Intelligence Webinar", "\n", "\n", "\n", "\n"]},
{"url": "https://blog.scrapinghub.com/a-practical-guide-to-web-data-qa-part-iv-complementing-semi-automated-techniques", "title": "A PRACTICAL GUIDE TO WEB DATA QA PART IV: COMPLEMENTING SEMI-AUTOMATED TECHNIQUES", "date": "September 03, 2020 ", "author": "Ivan Ivanov and Warley Ferreira Lopes", "no_comment": "0 Comments", "content": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "http://quotes.toscrape.com/tag/love/", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "."]},
{"url": "https://blog.scrapinghub.com/blog-comments-api-beta-release", "title": "Blog Comments API (BETA):\u00a0Extract Blog Comment DATA At Scale", "date": "July 30, 2020 ", "author": "John Campbell", "no_comment": "0 Comments", "content": ["\n", "\n", "\n", "\n", "\n", "\n", ",", "\n", "\n", "\n", "\n", "natural language understanding (NLU)", "\n", "\n", "\n", "reliably", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Learn more about the API in the documentation.", "\n", "\n", "\n", "\n", "\n", "\n", "Read the documentation", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://blog.scrapinghub.com/a-practical-guide-to-web-data-qa-part-v-broad-crawls", "title": "A Practical Guide to Web Data QA Part V: Broad Crawls", "date": "September 30, 2020 ", "author": "Ivan Ivanov", "no_comment": "0 Comments", "content": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Dynamic programming", "Divide-and-conquer algorithm", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://blog.scrapinghub.com/large-scale-web-scraping", "title": "Large scale web scraping", "date": "January 14, 2021 ", "author": "Attila T\u00f3th", "no_comment": "0 Comments", "content": ["\n", "Is it all about proxies?", "\n", "It is fairly intertwined. Using good quality proxies is surely important. If you use blacklisted proxies, even the best scraper logic will not yield good results.", "\n", "\n", "However, a good circumvention logic of the scraper that is in tune with the requirement of the website is equally important. Over the years, antibots have shifted from server-side validation to client-side validation where they look at javascript and browser fingerprinting, etc\u2026", "\n", "So really, it depends a lot on the target website. Most of the time, decent proxies combined with good crawling knowledge and accrual strategy should do the trick and deliver acceptable results.", "\n", "When you start getting blocks...", "\n", "Bans and antibots are primarily designed to prevent the abuse of a website and it is very important to ", ".", "\n", "Thus, the first thing before even starting a web scraping project is to understand the website you are trying to scrape. Your crawls should be well under the total number of users that a website has the infrastructure to successfully serve and never exceed the number of resources the website has. Staying respectful to the website will take you a long way for your scraping project.", "\n", "If you are still ", ", here are a few basic checkpoints:", "\n", "Check if your headers are able to mimic real-world browsers.", "The next step would be to check if the website has enabled geo-blocking. Using region-specific proxies may help here. ", "Residential proxies may be useful in case the website is blocking data center proxies.", "Then it comes down to your crawl strategy. You should be careful before hitting the predicted ajax or mobile endpoints and try to be organic and follow the site-map.", "If you start getting white-listed sessions, leverage those by creating a good cookie handling and session management strategy.", "Most of the websites vigorously check for browser fingerprints and employ javascript in a big way so your infrastructure should be designed to handle those challenges.", "\n", "Dealing with captchas", "\n", "The best thing to do against captchas is to ensure that you don't even get a captcha. Scraping politely might be enough in your case. If not, then using different types of proxies, regional proxies, and efficiently handling javascript challenges can reduce the chances of getting a captcha.", "\n", "Despite all the efforts, if you still get a captcha, you could try third party solutions or design a simple solution yourself to handle easy captchas.", "\n", "Factors to look at if you decide to outsource proxy management", "\n", "Managing proxies for web scraping is very complex and challenging, which is why many people prefer to outsource their proxy management. When choosing a proxy solution, what factors should you look at?", "\n", "It is very important to use a ", " that provides good quality as well as a good quantity of proxies that are spread across different regions. A good proxy solution should also provide added features like TLS fingerprinting, DCP/IP fingerprinting, header profiles, browser profiles, etc... so that requests don't return unsuccessfully. ", "\n", "If a provider offers a trial of their solution, it would be useful to test the success ratio against the target website. A provider that handles captchas seamlessly is a great bonus. The best situation would be if your proxy provider is GDPR compliant and provides responsibly sourced IPs. ", "\n", "We know it would be so much easier to just send a request and not worry about the proxies, which is why we are constantly working on improving our technology to ensure that our partners enjoy successful requests without dealing with the hassles of proxy management.", "\n", "We hope this short article helped answer your questions about good proxy management. If you have more questions, just leave them in the comments below and we will get back to you as soon as possible."]},
{"url": "https://blog.scrapinghub.com/web-data-extraction-summit-2020", "title": "Announcing The Web Data Extraction Summit 2020", "date": "September 24, 2020 ", "author": "Himanshi Bhatt", "no_comment": "0 Comments", "content": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "The stellar line-up", "\u00a0will share their expert knowledge on\u00a0", "topics", " like: Running a Business on Web Scraped Data,\u00a0 How Venture Capital Firms use Web Data to find Billion-Dollar Companies, and How to Build Your Own Price Monitoring Tool. Along with panels on Legal Compliance in the World of Web Scraping and Cutting Edge Ways to Tackle Anti-Bot Challenges.\u00a0", "\n", " With the range of topics covering everything from advanced-technical discussions to business know-how, at the Extract Summit, there is something for everyone. You can view the agenda here, and stay tuned as more talks are announced!", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://blog.scrapinghub.com/scrapy-cloud-secrets-hub-crawl-frontier-and-how-to-use-it", "title": "Scrapy Cloud Secrets: Hub Crawl Frontier and How To Use It", "date": "August 06, 2020 ", "author": "J\u00falio C\u00e9sar Batista", "no_comment": "0 Comments", "content": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "<YOUR PROJECT ID>", "<YOUR API KEY>", "\n", "\n", "<YOUR PROJECT ID>", "<YOUR API KEY>", "\n", "\n", "\n", "\n", "<YOUR PROJECT ID>", "<YOUR API KEY>", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://blog.scrapinghub.com/news-article-data-extraction-open-source-vs.-closed-source-solutions", "title": "News & Article Data Extraction: Open Source vs Closed Source Solutions", "date": "September 10, 2020 ", "author": "Attila T\u00f3th", "no_comment": "0 Comments", "content": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Cleaned HTML", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Html-text ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "In this whitepaper", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]},
{"url": "https://blog.scrapinghub.com/web-scraping-real-estate-data-use-cases", "title": "Real Estate: Use Web Data Extraction to Make Smarter Decisions", "date": "August 27, 2020 ", "author": "Attila T\u00f3th", "no_comment": "0 Comments", "content": ["\n", "\n", "\n", "\n", "\n", "\n", "data scraping ", "partner", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]}
]